{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from transformers import MBartForConditionalGeneration, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = 'en_XX'\n",
    "tgt_lang = 'cr_CR'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_json('/home/yush/kreol-benchmark/data/lang_data/en-cr/en-cr_dev.jsonl',lines=True)\n",
    "val_inputs = list(val['input'])\n",
    "val_labels = list(val['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt1 =\"/home/yush/kreol-benchmark/checkpoint_tests/checkpoint-120000_best\"\n",
    "tokenizer_1 = AutoTokenizer.from_pretrained(ckpt1)\n",
    "\n",
    "tokenizer_1.src_lang=src_lang\n",
    "tokenizer_1.tgt_lang=tgt_lang\n",
    "\n",
    "input_tokens_1 = tokenizer_1(val_inputs,max_length=128, truncation=True, padding=\"max_length\",return_tensors='pt')\n",
    "\n",
    "mdl_1 = MBartForConditionalGeneration.from_pretrained(ckpt1)\n",
    "mdl_1 = mdl_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt2 =\"/home/yush/kreol-benchmark/checkpoint_tests/checkpoint-11_best500ft\"\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(ckpt2)\n",
    "\n",
    "tokenizer_2.src_lang=src_lang\n",
    "tokenizer_2.tgt_lang=tgt_lang\n",
    "\n",
    "input_tokens_2 = tokenizer_2(val_inputs,max_length=128, truncation=True, padding=\"max_length\",return_tensors='pt')\n",
    "\n",
    "mdl_2 = MBartForConditionalGeneration.from_pretrained(ckpt2)\n",
    "mdl_2 = mdl_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_slice_dict(dicti,slice_begin,slice_end=None):\n",
    "    sliced_dict = {}\n",
    "    for k,v in dicti.items():\n",
    "        if slice_end:\n",
    "            sliced_dict[k] = v[slice_begin:slice_end]\n",
    "        else:\n",
    "            sliced_dict[k] = v[slice_begin:]\n",
    "    return sliced_dict\n",
    "\n",
    "def generate_output(input_tokens,model,tokenizer,batch_num=5):\n",
    "    batch_size = len(val_inputs) // batch_num\n",
    "    output = []\n",
    "    for i in range(0,len(val_inputs),batch_size):\n",
    "        input_dict = index_slice_dict(input_tokens,i,i+batch_size)\n",
    "        input_dict = {k:v.to(device) for k,v in input_dict.items()}\n",
    "        output_tokens_bn = model.generate(**input_dict)\n",
    "        output_batch = tokenizer.batch_decode(output_tokens_bn, skip_special_tokens=True)\n",
    "        output.extend(output_batch)\n",
    "        torch.cuda.empty_cache()\n",
    "    # input_tokens = {k:v.to('cpu') for k,v in input_tokens.items()}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_1 = generate_output(input_tokens_1,mdl_1,tokenizer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_1 = generate_output(input_tokens_1,mdl_1,tokenizer_1)\n",
    "torch.cuda.empty_cache()\n",
    "output_2 = generate_output(input_tokens_2,mdl_2,tokenizer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Some day you will see that horrible hhingh in the holy place, just as the prophet Daniel said.\n",
      "SOTA: Enn zour zot pou trouve ki fighting dan plas sakre, kouma profetgamot finn dir.\n",
      "FtSOTA: Enn zour zot pou trouv, dan plas sakre, kouma profet finn dir.\n",
      "Label: Alor ler zot trouv bann sakrilez abominab parey kouma Profet Daniel ti anonse.\n",
      "------------\n",
      "Input: God gives such beauty to everything that grows in the fields, even though it is here today and thrown into a fire tomorrow.\n",
      "SOTA: Bondie donn sa bote la tou seki grandi dan karo, mem si li isi e zet li dan dife demin.\n",
      "FtSOTA: Bondie donn sa bote la tou seki grandi dan karo mem si li isi e zet li dan dife demin.\n",
      "Label: Bondie donn enn bote tou seki pous dan karo, mem si zot la azordi e pou zet dan dife dime.\n",
      "------------\n",
      "Input: The disciples were shocked when they saw how quickly the tree had dried up.\n",
      "SOTA: Bann disip ti soke kan zot ti trouv ki vites pie la ti sek.\n",
      "FtSOTA: Bann disip ti soke kan zot ti trouv ki vites pie la ti sek.\n",
      "Label: Ler bann disip trouv sa, zot ti etone, kouma sa pie la kapav sek enn sel kou.\n",
      "------------\n",
      "Input: But there was also a Muslim family there, and at the end of the lane there were, like I said before, the Mazanbiks.\n",
      "SOTA: Me ti ena enn fami Mizilman laba e dan fon lenpas ti ena, kouma mo ti dir avan, bann Mazanbik.\n",
      "FtSOTA: Me ti ena enn fami Mizilman ek dan fon lenpas ti ena, kouma mo ti dir avan, bann Mazanbik.\n",
      "Label: Me ti ena osi enn fami Mizilman e dan finision lenpas ti ena, kouma mo ti dir zot, bann Mazanbik.\n",
      "------------\n",
      "Input: At that time a well-known terrorist named Jesus Barabbas was in jail.\n",
      "SOTA: Sa lepok la, enn zanimo bien koni ki ti apel Zezi Barabas, ti dan prizon.\n",
      "FtSOTA: Sa lepok la enn bien koni ki ti apel Zezi Barabas ti dan prizon-la.\n",
      "Label: Sa moman-la, ti ena enn prizonie teroris ki tou dimounn kone, li ti apel Barabas.\n",
      "------------\n",
      "Input: This is one of the principles of democracy in which we believe or do not believe.\n",
      "SOTA: Sa li enn-de bann prensip demokrasi dan lekel nu krwar ubyen nu pa krwar.\n",
      "FtSOTA: Sa li enn-de bann prensip demokrasi ki nou krwar ousa nou pa krwar.\n",
      "Label: Se enn bann prinsip demokrasi ki nou krwar ou nou pa krwar.\n",
      "------------\n",
      "Input: Or this one, riddled with debt, has already promised his daughter to a Roman senator as repayment.\n",
      "SOTA: Ubyen sannla, ranpli ar andete, finn deza promet so tifi a enn peyman Romin.\n",
      "FtSOTA: Ouswa sa enn zedmo-la, ranpli ar andete, finn deza promet so tifi a enn tifi Romin kouma repayman.\n",
      "Label: Me li ti ranpli ar det e li ti deza promet so tifi enn senater romin kont ranboursman.\n",
      "------------\n",
      "Input: Asbestos is bad for health as it can lead to cancer.\n",
      "SOTA: Asbestos li move pu lasante akoz li kapav amenn kanser.\n",
      "FtSOTA: Asbestos li move pou lasante parski li kapav amenn enn kanser.\n",
      "Label: Asbestos move pou la sante parski li kapav fer gagn kanser.\n",
      "------------\n",
      "Input: I have often wanted to gather your people, as a hen gathers her chicks under her wings.\n",
      "SOTA: Mo finn toultan anvi zwenn ou dimounn, kouma enn poul zwenn so lipie anba so lezel.\n",
      "FtSOTA: Mo finn toultan anvi zwenn to bann dimounn, kouma enn poul zwenn so lekor anba so lezel.\n",
      "Label: Konbien fwa mo finn anvi rasanble to bann zanfan kouma enn mama poul rasanble so bann piti anba so lezel.\n",
      "------------\n",
      "Input: He trusted God, so let God save him, if he wants to and he even said he was God's Son.\n",
      "SOTA: Li ti fer Bondie konfians e si li anvi e li ti mem dir ki li ti Garson Bondie.\n",
      "FtSOTA: Li ti fer Bondie konfians e si li anvi e li ti mem dir ki li ti Garson Bondie.\n",
      "Label: Li finn met so konfians dan Bondie, si vremem Bondie oule, dir li vinn delivre li e li finn dir, li Garson Bondie.\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "r = list(np.random.randint(0,500,10))\n",
    "for i in r:\n",
    "    print(f\"Input: {val_inputs[i]}\")\n",
    "    print(f\"SOTA: {output_1[i]}\")\n",
    "    print(f\"FtSOTA: {output_2[i]}\")\n",
    "    print(f\"Label: {val_labels[i]}\")\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
