{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from transformers import MBart50Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MBart50Tokenizer.from_pretrained(\"/mnt/disk/yrajcoomar/kreol-benchmark/pipelines/tok\",max_len=256)\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint/checkpoint-72000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mo pa pou lev twa kot to ete?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_english_phrase = \"I will not follow you wherever you go\"\n",
    "\n",
    "inputs = tokenizer(example_english_phrase, return_tensors=\"pt\")\n",
    "\n",
    "generated_tokens = model.generate(**inputs)\n",
    "\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "val = pd.read_json('/mnt/disk/yrajcoomar/kreol-benchmark/experiments/data/en-cr/en-cr_dev.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs = list(val['input'])\n",
    "val_labels = list(val['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = tokenizer(val_inputs,max_length=128, truncation=True, padding=\"max_length\",return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/cuda11/lib/python3.10/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_tokens = model.generate(**input_tokens)\n",
    "output = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.04176882522734308,\n",
       " 'precisions': [0.4168018164125851,\n",
       "  0.11048358630427109,\n",
       "  0.03871467286101433,\n",
       "  0.013056506849315069],\n",
       " 'brevity_penalty': 0.6013395530687732,\n",
       " 'length_ratio': 0.6628682003870136,\n",
       " 'translation_length': 6166,\n",
       " 'reference_length': 9302}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=output,references=val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I did not come to do away with them, but to give them their full meaning.\n",
      "Prediction: Mo pa ti vini avek zot, me zot ti fer zot per zot.\n",
      "Label: Mo pa finn vini pou aboli me pou donn zot zot vre sinifikasion.\n",
      "------------\n",
      "Input: The fact is, at the time, you had to pay the teacher in order to go to school.\n",
      "Prediction: Letan zot al lekol, zot ti fer nwaye dan lekol.\n",
      "Label: Anverite sa lepok la pou al lekol ti ena enn fiz pou pey profeser.\n",
      "------------\n",
      "Input: Angina can be described as a discomfort, heaviness, pressure, aching, burning.\n",
      "Prediction: Antrefwa “mili” enn antropolog, dibwa, par lafors gravite.\n",
      "Label: Nou capav dekrir anzinn couma enn sensasion inkonfortab, lourder, presion.\n",
      "------------\n",
      "Input: The boy said he would, but he didn't go.\n",
      "Prediction: Bann garson la ti pou al plis, me li pa ti ale.\n",
      "Label: Garson-la reponn wi papa, li pou ale me li pa ale.\n",
      "------------\n",
      "Input: Was it God in heaven or merely some human being?\n",
      "Prediction: Eski u ti dan enn lot ka?\n",
      "Label: Eski sa ti sorti depi dan lesiel ouswa dimoun ki finn invant sa?\n",
      "------------\n",
      "Input: After finding a very valuable one, the owner goes and sells everything in order to buy that pearl.\n",
      "Prediction: Apre enn timoman reflexion bann li byen konpran e li dimann li si nou omisyon\n",
      "Label: Ler li trouv enn ki ena enn bel valer, li al vann tou seki li ena pou al aste sa perl la.\n",
      "------------\n",
      "Input: They paid it for a potter's field, as the Lord had commanded me.\n",
      "Prediction: Zot ti dibout li enn povve ar mwa.\n",
      "Label: Zot finn servi sa kas la pou aste later potie kouma Lesegner finn donn lord.\n",
      "------------\n",
      "Input: So when you go to a town or a village, find someone worthy enough to have you as their guest and stay with them until you leave.\n",
      "Prediction: Alor kan u al lapes ubyen enn dimunn e zot bizin kit zot plis e gagn zot\n",
      "Label: Alors ninport ki lavil ou vilaz ki zot rantre, rod kisannla ki pare pou akeyir zot, res kot li ziska zot depar.\n",
      "------------\n",
      "Input: When they got there, he told them, sit here while I go over there and pray.\n",
      "Prediction: Kan zot rant isi, li ariv lakaz.\n",
      "Label: Kan zot ariv laba, li dir bann-la, res la, mwa mo pe al inpe pli lwin pou priye.\n",
      "------------\n",
      "Input: He went to the chief priests and asked, how much will you give me if I help you arrest Jesus?\n",
      "Prediction: Li ti al kot pret, e ler zot ti dimann mwa si mo pou ed zot\n",
      "Label: Li al zwenn bann sef pret e li dir zot, komie zot pou donn mwa si mo livre zot Zezi?\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Input: {val_inputs[i]}\")\n",
    "    print(f\"Prediction: {output[i]}\")\n",
    "    print(f\"Label: {val_labels[i]}\")\n",
    "    print('------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I did not come to do away with them, but to give them their full meaning.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mo pa finn vini pou aboli me pou donn zot zot vre sinifikasion.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mo pa vinn zwenn zot, me zot ti pe dimann zot.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(output, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 20004,   890,   101,   230,  1196,    81, 19941,   190,    81,\n",
       "            32,    68,  1104,    81, 19940,     2]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I did not come to do away with them, but to gi...</td>\n",
       "      <td>Mo pa finn vini pou aboli me pou donn zot zot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The fact is, at the time, you had to pay the t...</td>\n",
       "      <td>Anverite sa lepok la pou al lekol ti ena enn f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angina can be described as a discomfort, heavi...</td>\n",
       "      <td>Nou capav dekrir anzinn couma enn sensasion in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The boy said he would, but he didn't go.</td>\n",
       "      <td>Garson-la reponn wi papa, li pou ale me li pa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was it God in heaven or merely some human being?</td>\n",
       "      <td>Eski sa ti sorti depi dan lesiel ouswa dimoun ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>The angel answered, the Holy Spirit will come ...</td>\n",
       "      <td>Anz la reponn, Lespri Sin pou vinn lor twa, e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>At its end, it had a whole lot of Flame-Trees ...</td>\n",
       "      <td>Dan so finision, de kote sime, ti ena enn ta p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>The king will answer, whenever you did it for ...</td>\n",
       "      <td>Lerla lerwa reponn zot, sak fwa ki zot finn fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>You Pharisees and teachers of the Law of Moses...</td>\n",
       "      <td>Maler lor zot profeser lalwa Moiz ek Farizien,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Yet Wisdom is shown to be right by his good ac...</td>\n",
       "      <td>Pourtan li finn demontre lasazes Bondie par so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 input  \\\n",
       "0    I did not come to do away with them, but to gi...   \n",
       "1    The fact is, at the time, you had to pay the t...   \n",
       "2    Angina can be described as a discomfort, heavi...   \n",
       "3             The boy said he would, but he didn't go.   \n",
       "4     Was it God in heaven or merely some human being?   \n",
       "..                                                 ...   \n",
       "495  The angel answered, the Holy Spirit will come ...   \n",
       "496  At its end, it had a whole lot of Flame-Trees ...   \n",
       "497  The king will answer, whenever you did it for ...   \n",
       "498  You Pharisees and teachers of the Law of Moses...   \n",
       "499  Yet Wisdom is shown to be right by his good ac...   \n",
       "\n",
       "                                                target  \n",
       "0    Mo pa finn vini pou aboli me pou donn zot zot ...  \n",
       "1    Anverite sa lepok la pou al lekol ti ena enn f...  \n",
       "2    Nou capav dekrir anzinn couma enn sensasion in...  \n",
       "3    Garson-la reponn wi papa, li pou ale me li pa ...  \n",
       "4    Eski sa ti sorti depi dan lesiel ouswa dimoun ...  \n",
       "..                                                 ...  \n",
       "495  Anz la reponn, Lespri Sin pou vinn lor twa, e ...  \n",
       "496  Dan so finision, de kote sime, ti ena enn ta p...  \n",
       "497  Lerla lerwa reponn zot, sak fwa ki zot finn fe...  \n",
       "498  Maler lor zot profeser lalwa Moiz ek Farizien,...  \n",
       "499  Pourtan li finn demontre lasazes Bondie par so...  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    \n",
    "    preds, labels = eval_preds\n",
    "    # In case the model returns more than the prediction logits\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100s in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"score\"]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
