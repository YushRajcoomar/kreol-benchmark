{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import MBart50Tokenizer\n",
    "import tqdm\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_json('/home/yush/kreol-benchmark/data/lang_data/en-cr/en-cr_dev.jsonl',lines=True)\n",
    "val_inputs = list(val['input'])\n",
    "val_labels = list(val['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = os.listdir('/home/yush/kreol-benchmark/checkpoint/MBart50/bidirectional')\n",
    "weights = sorted([x for x in weights if 'checkpoint' in x],key=lambda x: int(x.split('-')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_slice_dict(dicti,slice_begin,slice_end=None):\n",
    "    sliced_dict = {}\n",
    "    for k,v in dicti.items():\n",
    "        if slice_end:\n",
    "            sliced_dict[k] = v[slice_begin:slice_end]\n",
    "        else:\n",
    "            sliced_dict[k] = v[slice_begin:]\n",
    "    return sliced_dict\n",
    "\n",
    "def eval_batches_on_gpu(model,tokenizer,input_tokens,val,batch_num):\n",
    "    batch_size = len(val) // batch_num\n",
    "    output = []\n",
    "    for i in range(0,len(val),batch_size):\n",
    "        input_dict = index_slice_dict(input_tokens,i,i+batch_size)\n",
    "        output_tokens_bn = model.generate(**input_dict)\n",
    "        output_batch = tokenizer.batch_decode(output_tokens_bn, skip_special_tokens=True)\n",
    "        output.extend(output_batch)\n",
    "        torch.cuda.empty_cache()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = 'en_XX'\n",
    "tgt_lang = 'cr_CR'\n",
    "\n",
    "bidirectional = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = '/home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune'\n",
    "weights_hq = [x for x in os.listdir(weights_dir) if 'dabre' in x]\n",
    "weights_hq = sorted(weights_hq, key=lambda x: int(x.split('_')[-1][2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics for en_XX -> cr_CR at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq500/checkpoint-1384\n",
      "{'score': 45.19214507281211, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.21449912352692466, 'precisions': [0.5818284424379232, 0.2922248803827751, 0.16310432569974553, 0.09319385952995517], 'brevity_penalty': 0.9513367927972872, 'length_ratio': 0.9524833369167921, 'translation_length': 8860, 'reference_length': 9302}\n",
      "----------------\n",
      "Evaluation Metrics for cr_CR -> en_XX at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq500\n",
      "{'score': 47.29599650038933, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.23309650890088893, 'precisions': [0.5536822507240381, 0.28904886561954624, 0.17258883248730963, 0.10688050930460333], 'brevity_penalty': 1.0, 'length_ratio': 1.013735975673692, 'translation_length': 9668, 'reference_length': 9537}\n",
      "----------------\n",
      "Evaluation Metrics for en_XX -> cr_CR at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq500/checkpoint-692\n",
      "{'score': 44.26005918453428, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.2091268593910378, 'precisions': [0.5770670296019054, 0.28399663340146686, 0.15837277728028656, 0.09182836840666848], 'brevity_penalty': 0.9464781703751868, 'length_ratio': 0.9478606751236294, 'translation_length': 8817, 'reference_length': 9302}\n",
      "----------------\n",
      "Evaluation Metrics for cr_CR -> en_XX at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq500\n",
      "{'score': 46.194492422828134, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.22572574307110913, 'precisions': [0.5464003329171868, 0.28072870939420547, 0.1658151416627961, 0.10207100591715976], 'brevity_penalty': 1.0, 'length_ratio': 1.007864108210129, 'translation_length': 9612, 'reference_length': 9537}\n",
      "----------------\n",
      "Evaluation Metrics for en_XX -> cr_CR at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq2000/checkpoint-1446\n",
      "{'score': 45.446101424530156, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.22043007383650662, 'precisions': [0.5820661896243292, 0.29405495026054, 0.16578549848942598, 0.09764942914707858], 'brevity_penalty': 0.9607636580284806, 'length_ratio': 0.9615136529778542, 'translation_length': 8944, 'reference_length': 9302}\n",
      "----------------\n",
      "Evaluation Metrics for cr_CR -> en_XX at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq2000\n",
      "{'score': 47.25775395999429, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.23881982080647415, 'precisions': [0.5568643802772856, 0.29429231276806334, 0.17770278133364367, 0.11170147040652416], 'brevity_penalty': 1.0, 'length_ratio': 1.005871867463563, 'translation_length': 9593, 'reference_length': 9537}\n",
      "----------------\n",
      "Evaluation Metrics for en_XX -> cr_CR at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq2000/checkpoint-723\n",
      "{'score': 45.022563919989, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.21720265555272017, 'precisions': [0.5811113600717006, 0.291241395680038, 0.1621246530406258, 0.09600107715093577], 'brevity_penalty': 0.9587507617758123, 'length_ratio': 0.9595785852504838, 'translation_length': 8926, 'reference_length': 9302}\n",
      "----------------\n",
      "Evaluation Metrics for cr_CR -> en_XX at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq2000\n",
      "{'score': 46.60075272600005, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.2255732482909318, 'precisions': [0.5484908204543097, 0.28180724209605074, 0.16630019673648883, 0.10072472669205257], 'brevity_penalty': 1.0, 'length_ratio': 1.0109048967180454, 'translation_length': 9641, 'reference_length': 9537}\n",
      "----------------\n",
      "Evaluation Metrics for en_XX -> cr_CR at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq5000/checkpoint-1570\n",
      "{'score': 45.45033439310595, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.2201679272647038, 'precisions': [0.5798234834096749, 0.2934563956928174, 0.16513646082253805, 0.09782608695652174], 'brevity_penalty': 0.9615454014235794, 'length_ratio': 0.9622661793162761, 'translation_length': 8951, 'reference_length': 9302}\n",
      "----------------\n",
      "Evaluation Metrics for cr_CR -> en_XX at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq5000\n",
      "{'score': 47.291408650870686, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.23661400754891007, 'precisions': [0.5557522123893806, 0.29335529928610654, 0.1768739105171412, 0.10869833436150525], 'brevity_penalty': 1.0, 'length_ratio': 1.0071301247771836, 'translation_length': 9605, 'reference_length': 9537}\n",
      "----------------\n",
      "Evaluation Metrics for en_XX -> cr_CR at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq5000/checkpoint-785\n",
      "{'score': 45.31147338956064, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.21711671627187984, 'precisions': [0.5714128883521792, 0.2855151585550006, 0.15932914046121593, 0.09304770666316205], 'brevity_penalty': 0.9790350490678962, 'length_ratio': 0.9792517738120834, 'translation_length': 9109, 'reference_length': 9302}\n",
      "----------------\n",
      "Evaluation Metrics for cr_CR -> en_XX at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq5000\n",
      "{'score': 46.57638115717877, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.22701474348145723, 'precisions': [0.5496420790538438, 0.2841667578509684, 0.16714897557587685, 0.10173239955768522], 'brevity_penalty': 1.0, 'length_ratio': 1.0106951871657754, 'translation_length': 9639, 'reference_length': 9537}\n",
      "----------------\n",
      "Evaluation Metrics for en_XX -> cr_CR at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq10000/checkpoint-890\n",
      "{'score': 45.17066792164344, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.21445280222329258, 'precisions': [0.570079086115993, 0.28417015341701535, 0.15695952615992104, 0.09074171488690164], 'brevity_penalty': 0.9784861154261182, 'length_ratio': 0.978714254998925, 'translation_length': 9104, 'reference_length': 9302}\n",
      "----------------\n",
      "Evaluation Metrics for cr_CR -> en_XX at /home/yush/kreol-benchmark/checkpoint/MBart50/finetune/bidirectional/dabre_finetune/dabre_hq10000\n",
      "{'score': 46.565281871960224, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.22901650106432664, 'precisions': [0.545022226816913, 0.2824593916930121, 0.1690303239940044, 0.10571393613116359], 'brevity_penalty': 1.0, 'length_ratio': 1.014260249554367, 'translation_length': 9673, 'reference_length': 9537}\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "batch_num=5\n",
    "for weight_ckpt in weights_hq:\n",
    "    ckpt_dir = os.path.join(weights_dir,weight_ckpt)\n",
    "    weights = os.listdir(ckpt_dir)\n",
    "    for ckpt in weights:\n",
    "        checkpoint = os.path.join(ckpt_dir,ckpt)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        tokenizer.src_lang = src_lang\n",
    "        tokenizer.tgt_lang = tgt_lang\n",
    "        model = MBartForConditionalGeneration.from_pretrained(checkpoint)\n",
    "        model = model.to(device)\n",
    "        input_tokens = tokenizer(val_inputs,max_length=128, truncation=True, padding=\"max_length\",return_tensors='pt').to(device)\n",
    "        output = eval_batches_on_gpu(model,tokenizer,input_tokens,val,batch_num)\n",
    "        print(f'Evaluation Metrics for {src_lang} -> {tgt_lang} at {checkpoint}')\n",
    "        print(chrf.compute(predictions=output,references=val_labels))\n",
    "        print(bleu.compute(predictions=output,references=val_labels))\n",
    "        print('----------------')\n",
    "        if bidirectional:\n",
    "            val_inputs_bi, val_labels_bi = val_labels,val_inputs\n",
    "            tokenizer.src_lang,tokenizer.tgt_lang = tokenizer.tgt_lang,tokenizer.src_lang\n",
    "            input_tokens = tokenizer(val_inputs_bi,max_length=128, truncation=True, padding=\"max_length\",return_tensors='pt').to(device)\n",
    "            output = eval_batches_on_gpu(model,tokenizer,input_tokens,val,batch_num)\n",
    "            print(f'Evaluation Metrics for {tgt_lang} -> {src_lang} at {checkpoint}')\n",
    "            print(chrf.compute(predictions=output,references=val_labels_bi))\n",
    "            print(bleu.compute(predictions=output,references=val_labels_bi))\n",
    "            print('----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
