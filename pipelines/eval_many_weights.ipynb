{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import MBart50Tokenizer\n",
    "import tqdm\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_json('/mnt/disk/yrajcoomar/kreol-benchmark/data/lang_data/en-cr/en-cr_dev.jsonl',lines=True)\n",
    "val_inputs = list(val['input'])\n",
    "val_labels = list(val['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "chrf = evaluate.load(\"chrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = os.listdir('/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint/checkpoint-140000\n",
      "{'score': 44.84547543879345, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.2206957217203022, 'precisions': [0.5968494749124854, 0.3073110285006196, 0.17582562747688243, 0.10352142554094187], 'brevity_penalty': 0.9181318826103453, 'length_ratio': 0.9213072457536013, 'translation_length': 8570, 'reference_length': 9302}\n",
      "----------------\n",
      "/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint/checkpoint-20000\n",
      "{'score': 43.9885408439185, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.21161918530428125, 'precisions': [0.5817245817245817, 0.29476823660991675, 0.16960381608586192, 0.0981838819523269], 'brevity_penalty': 0.9154540673427985, 'length_ratio': 0.9188346592130725, 'translation_length': 8547, 'reference_length': 9302}\n",
      "----------------\n",
      "/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint/checkpoint-60000\n",
      "{'score': 43.022916426277334, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.20311427379314842, 'precisions': [0.5883829329508784, 0.2938858522943943, 0.16492466404235104, 0.09331780462949484], 'brevity_penalty': 0.8942691057910551, 'length_ratio': 0.8994839819393678, 'translation_length': 8367, 'reference_length': 9302}\n",
      "----------------\n",
      "/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint/checkpoint-40000\n",
      "{'score': 44.01573720751398, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.21017400626875196, 'precisions': [0.588428588193874, 0.29522503428500185, 0.16686610823028852, 0.0971233266875534], 'brevity_penalty': 0.9124190507833595, 'length_ratio': 0.9160395613846485, 'translation_length': 8521, 'reference_length': 9302}\n",
      "----------------\n",
      "/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint/checkpoint-120000\n",
      "{'score': 45.33915303623491, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.22481650232675818, 'precisions': [0.5968356623166647, 0.3087388160313764, 0.17717717717717718, 0.1053072625698324], 'brevity_penalty': 0.9284321298085454, 'length_ratio': 0.930875080627822, 'translation_length': 8659, 'reference_length': 9302}\n",
      "----------------\n",
      "/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint/checkpoint-30000\n",
      "{'score': 43.93219357390389, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.21302843597496965, 'precisions': [0.5852023121387283, 0.2952147239263804, 0.1665359477124183, 0.09676968256187946], 'brevity_penalty': 0.927394977661672, 'length_ratio': 0.9299075467641368, 'translation_length': 8650, 'reference_length': 9302}\n",
      "----------------\n",
      "/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint/checkpoint-100000\n",
      "{'score': 44.762328330347216, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.21912869341036623, 'precisions': [0.5968444601436477, 0.30564243713249095, 0.17509675697317495, 0.10566199599656849], 'brevity_penalty': 0.909141150471259, 'length_ratio': 0.9130294560309611, 'translation_length': 8493, 'reference_length': 9302}\n",
      "----------------\n",
      "/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint/checkpoint-90000\n",
      "{'score': 43.95595976980054, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.21477393179739254, 'precisions': [0.5857774674115456, 0.29745427582797823, 0.16978398314014753, 0.10009868884816016], 'brevity_penalty': 0.9206871281307047, 'length_ratio': 0.9236723285314986, 'translation_length': 8592, 'reference_length': 9302}\n",
      "----------------\n",
      "/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint/checkpoint-80000\n",
      "{'score': 43.719825795431994, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "{'bleu': 0.21109941428767898, 'precisions': [0.5892878163625662, 0.2981863664790494, 0.16877918612408271, 0.09791309319611206], 'brevity_penalty': 0.9093756106726828, 'length_ratio': 0.9132444635562245, 'translation_length': 8495, 'reference_length': 9302}\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for ckpt in weights:\n",
    "    checkpoint = os.path.join('/mnt/disk/yrajcoomar/kreol-benchmark/checkpoint',ckpt)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    model = MBartForConditionalGeneration.from_pretrained(checkpoint)\n",
    "    model = model.to(device)\n",
    "    input_tokens = tokenizer(val_inputs,max_length=128, truncation=True, padding=\"max_length\",return_tensors='pt').to(device)\n",
    "    output_tokens = model.generate(**input_tokens)\n",
    "    output = tokenizer.batch_decode(output_tokens, skip_special_tokens=True)\n",
    "    print(checkpoint)\n",
    "    print(chrf.compute(predictions=output,references=val_labels))\n",
    "    print(bleu.compute(predictions=output,references=val_labels))\n",
    "    print('----------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
